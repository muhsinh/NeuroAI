{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/muhsinh/NeuroAI/blob/Unit-1/unit1\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HyLv7SnKrH0z"
      },
      "source": [
        "### Sk-learn Clustering & PCA Project!\n",
        "\n",
        "##### How to work through this project:\n",
        "- Go cell by cell and finish the marked #TODO's\n",
        "- You don't need to touch the code marked between the `#---------#`. Those are puzzle pieces that your code will fit into!\n",
        "    - However, I **STRONGLY** encourage you to understand every single line between those blocks. They are essential!\n",
        "    - It is crucial that your variable names are what we expect them to be, or the puzzle pieces won't fit.\n",
        "- Tutorials/helpful information will be placed in the `.md` cells above the \"work\" cells. Consult them if you are stuck.\n",
        "- If you REALLY cannot find the correct code to make the cell run, follow the Google Drive link at the bottom of this notebook to see expected answers and a completed notebook.\n",
        "    - Chances are your output won't be the exact same (stochasticity!) but it should be similar"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2xWzrQB0rH01"
      },
      "outputs": [],
      "source": [
        "# Get used to these imports!\n",
        "#----------------------------------------------------------------#\n",
        "#To install: pip install numpy\n",
        "import numpy as np\n",
        "#To install: pip install matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "#To install: pip install sklearn\n",
        "import sklearn\n",
        "#To install: pip install torchvision\n",
        "import torchvision as tv\n",
        "#----------------------------------------------------------------#"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ibWZJcFerH03"
      },
      "source": [
        "# NumPy and Shape\n",
        "\n",
        "### Basics of creating Numpy arrays\n",
        "\n",
        "This is by no means going to be an exhaustive tutorial on `numpy` as we have resources in Unit 0 for that. However, the following examples of numpy arrays (0, 1, and 2D) will be used to illustrate an important concept later. So run this cell and observe the output, and make sure you uinderstand what is going on."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Scalar (0D)\n",
        "## You probably won't need to make these often\n",
        "a = np.array(3.14159)\n",
        "print(f'0D array: \\n {a}')\n",
        "\n",
        "# Vector (1D)\n",
        "b = np.array([1,2,3,4,5])\n",
        "print(f'1D array: \\n {b}')\n",
        "\n",
        "# Matrix (2D)\n",
        "c = np.array([\n",
        "    [1,2,3],\n",
        "    [4,5,6],\n",
        "    [7,8,9]\n",
        "])\n",
        "print(f'2D array: \\n {c}')\n",
        "\n",
        "c2 = np.array([\n",
        "    [1,2],\n",
        "    [3,4],\n",
        "    [5,6],\n",
        "    [7,8],\n",
        "])\n",
        "print(f'Another 2D array: \\n {c2}')"
      ],
      "metadata": {
        "id": "tSyRwbTwwjMq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Shape of an array\n",
        "\n",
        "Before we move beyond this and peoples heads start exploding while trying to imagine 100D arrays, lets take a look at a very important component of arrayss called \"shape\" or \"size\".\n",
        "\n",
        "Shape is an incredibly important concept when it comes to working in numpy and PyTorch. If you are going to be doing ML/DL related research these are two packages you need to familiarize yourself with and this is a concept shared between them both.\n",
        "\n",
        "The shape of an array describes the size of each dimension, from the outermost to the innermost, of a array.\n",
        "\n",
        "### Hands-on time\n",
        "\n",
        "This can be hard to explain, so use this folowing example and the previous code cell to get an understanding of how this function works.\n",
        "\n",
        "NOTE: Numpy arrays cannot be jagged! All items in a list must be the same length.\n",
        "\n",
        "The syntax of how to access data \"shape\" is explained here:\n",
        "- [Data Shape in Numpy](https://numpy.org/doc/stable/reference/generated/numpy.shape.html)\n",
        "\n",
        "Read this to understand the code in the following cell.\n",
        "\n",
        "What do you think will be the output of the following cell?\n",
        "\n",
        "$\\color{red}{\\textit Your Answer:}$"
      ],
      "metadata": {
        "id": "Ln18UufDw57w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(a.shape)\n",
        "print(b.shape)\n",
        "print(c.shape)\n",
        "print(c2.shape)"
      ],
      "metadata": {
        "id": "XvE0pI-mx8v4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Pay attention!\n",
        "\n",
        "Take a look at the next part of this code and pay attention to the creation of these matricies and how their shapes are displayed in the console.\n",
        "\n",
        "This won't be directly relevant to this homework after this code cell, but is *very* important to know!"
      ],
      "metadata": {
        "id": "yD2gTDAhyqgl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Higher dimensional arrays (nD)\n",
        "## We will also show you in this section a few different ways to initialize arrays without passing in a scalar/vector/matrix\n",
        "\n",
        "d = np.zeros((3,3,3))\n",
        "print(f'Zeroed Square 3D array: \\n {d}')\n",
        "print(f'Zeroed Square 3D array size: \\n {d.shape}')\n",
        "\n",
        "d2 = np.ones((2,2,4,3))\n",
        "print(f'1-filled 4D array: \\n {d2}')\n",
        "print(f'1-filled 4D array size: \\n {d2.shape}')\n",
        "\n",
        "d2 = np.random.rand(2,3,5)\n",
        "print(f'Random 3D array: \\n {d2}')\n",
        "print(f'Random 3D array size: \\n {d2.shape}')"
      ],
      "metadata": {
        "id": "k3WAQqyCyAcR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Investigating MNIST data\n",
        "\n",
        "Below is the data and labels in two separate variables, find their shapes (this will make it easier to understand what you are working with)\n",
        "\n",
        "You need to write code for this part!"
      ],
      "metadata": {
        "id": "2VvG6jjy0If3"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tg4r0ororH03"
      },
      "outputs": [],
      "source": [
        "#----------------------------------------------------------------#\n",
        "all_data = tv.datasets.MNIST('./data', download=True)\n",
        "\n",
        "data = all_data.data.numpy()\n",
        "labels = all_data.targets.numpy()\n",
        "#----------------------------------------------------------------#\n",
        "## TODO: Find and print the shapes of data and labels\n",
        "# Print the shape of data and the shape of labels\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Please describe on a high level what you think this data is structured like based on the shape (i.e this dataset is a collection of what? vectors? 3D objects? Images?)\n",
        "\n",
        "$\\color{red}{\\textit Your Answer:}$"
      ],
      "metadata": {
        "id": "8ORTVnhSzJWk"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8_5X2CgdrH04"
      },
      "source": [
        "## Train/Test split\n",
        "\n",
        "One core tenant of ML is the independence assumption between your train and test sets. If you want **accurate metrics** on the performance of your model, you ***absolutley must not*** let there be **any** leak between the data that you train on and the data that you use to prove your model works.\n",
        "\n",
        "The three sets you create when you make models are as follows:\n",
        "- Train: The data that the model parameters will fit to and attempt to make new predictions based off of\n",
        "- Validation: The data that you use to evaluate the performance of the model so that you may tweak its hyperparameters (high level choices about the model that the model itself does not learn from the data)\n",
        "- Test: The data that you lock away and never touch until the VERY END. You should not even LOOK at this data!\n",
        "\n",
        "It should be always true that that:\n",
        "- $\\textrm{TRAIN} \\cap \\textrm{VAL} = ∅$\n",
        "- $\\textrm{TRAIN} \\cap \\textrm{TEST} = ∅$\n",
        "- $\\textrm{VAL} \\cap \\textrm{TEST} = ∅$,\n",
        "\n",
        "Please read more about splitting data into Train/Test:\n",
        "- [Importance of Train/Test](https://developers.google.com/machine-learning/crash-course/training-and-test-sets/splitting-data)\n",
        "\n",
        "Concretely, here is how you should do it with slicing numpy arrays\n",
        "- [Slicing Tutorial](https://www.learnbyexample.org/python-list-slicing/)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TGqkZwMQrH04"
      },
      "outputs": [],
      "source": [
        "# Goal: Split the data AND labels into train and test sets.\n",
        "# In reality, we won't be \"testing\" anything as these are unsupervised algorithms. This is good practice anyways!\n",
        "\n",
        "## TODO: Create the following variables\n",
        "# train_data: 1000 training data from the start of the all_data array\n",
        "# train_labels: 1000 labels associated w/ training data\n",
        "\n",
        "# test_data: 500 test data from the end of the all_data array\n",
        "# test_labels = 500 test labels associated w/ test data\n",
        "\n",
        "#----------------------------------------------------------------#\n",
        "print(f\"Train Data Shape:{train_data.shape}\") # = (1000, 28, 28)\n",
        "print(f\"Train Label Shape: {train_labels.shape}\") # = (1000,)\n",
        "\n",
        "print(f\"Test Data Shape:{test_data.shape}\") # = (500, 28, 28)\n",
        "print(f\"Test Label Shape: {test_labels.shape}\") # = (500,)\n",
        "#----------------------------------------------------------------#"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YDY3_cczrH04"
      },
      "outputs": [],
      "source": [
        "# Visualizes num_to_viz digits and labels with plt.matshow and plt.show. Notice how reshape is used to get the data into proper format for visualization.\n",
        "# Note the use of reshape!\n",
        "#----------------------------------------------------------------#\n",
        "num_of_digits_to_viz = 3\n",
        "for i in range(num_of_digits_to_viz):\n",
        "    to_reshape = train_data[i]\n",
        "    plt.matshow(to_reshape.reshape(28, 28))\n",
        "    plt.show()\n",
        "    print(f\"Associated Label: {train_labels[i]}\")\n",
        "#----------------------------------------------------------------#"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9alvszJerH04"
      },
      "source": [
        "# Performing PCA\n",
        "\n",
        "Now that you have the data, and understand its form, find out how to properly use PCA!\n",
        "Explore the concept of \"reshaping\" data below:\n",
        "- [Reshape](https://numpy.org/doc/stable/reference/generated/numpy.reshape.html)\n",
        "\n",
        "PCA does not work directly on raw images (2D Arrays) stacked together (3D array) but rather vectors (1D arrays) stacked to become a matrix (2D array). MNIST has image data, so we must take those images and turn them into vectors.\n",
        "\n",
        "Here is the syntax needed to perform PCA on your reshaped data.\n",
        "- [PCA](https://scikit-learn.org/stable/modules/generated/sklearn.decomposition.PCA.html)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "afYTOqsXrH05"
      },
      "outputs": [],
      "source": [
        "from sklearn.decomposition import PCA\n",
        "\n",
        "# Goal: Reduce the train data using PCA and visualize it\n",
        "\n",
        "## TODO: Create the following variables and execute the following code\n",
        "# reduced_data: PCA'ed training data\n",
        "\"\"\"\n",
        "Tips:\n",
        "- You will need to reshape the data before passing it into PCA. PCA takes data in the shape (X, Z). i.e, it must 2-d. Your data is currently (X, Y, Y)\n",
        "    - Think about how 2-d images can be vectorized, and how to maintain the X throughout the reshape\n",
        "- The important method for PCA is fit_transform\n",
        "    - Parameter n_components is the amount of dimensions PCA reduces to\n",
        "- Be sure to save the PCA'ed data into the proper variable name so it fits in with the provided puzzle pieces\n",
        "\"\"\"\n",
        "\n",
        "#----------------------------------------------------------------#\n",
        "rd = reduced_data.transpose()\n",
        "colors = [\"red\", \"orange\", \"yellow\", \"green\", \"cyan\", \"indigo\", \"pink\", \"chocolate\", \"grey\", \"lime\"]\n",
        "fig, ax = plt.subplots()\n",
        "for g in np.unique(train_labels):\n",
        "    idxs = np.where(train_labels == g)\n",
        "    ax.scatter(rd[0][idxs], rd[1][idxs], color=colors[g], label=f\"Digit {g}\")\n",
        "ax.legend()\n",
        "#----------------------------------------------------------------#\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ep5Qtmt4rH05"
      },
      "source": [
        "# t-SNE\n",
        "\n",
        "Uh oh... Did PCA not work? Take a look at the data. A lot of numbers are meshing together, but ones that look similar are close (like 2 and 3),\n",
        "and those that don't look similar are not very close (like 0 and 1)\n",
        "\n",
        "PCA preserves **global structure** of the N-D data, but does not preserve local structure, hence the heavy overlapping.\n",
        "We will now use another dimensionality reduction technique (t-SNE) that preserves local structure to see a proper reduction!\n",
        "\n",
        "Check out t-SNE\n",
        "- [t-SNE Documentation](https://scikit-learn.org/stable/modules/generated/sklearn.manifold.TSNE.html)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NYNm3VjXrH05"
      },
      "outputs": [],
      "source": [
        "from sklearn.manifold import TSNE\n",
        "\n",
        "# Goal: Reduce the train data using t-SNE and visualize it\n",
        "\n",
        "## TODO: Create the following variables and execute the following code\n",
        "# reduced_data: TSNE'ed training data\n",
        "\"\"\"\n",
        "Tips:\n",
        "- You literally just need to copy your code (if it works) from the above code cell and change PCA to TSNE\n",
        "- Call fit_transform on your new t-SNE object\n",
        "\"\"\"\n",
        "\n",
        "#----------------------------------------------------------------#\n",
        "rd = reduced_data.transpose()\n",
        "colors = [\"red\", \"orange\", \"yellow\", \"green\", \"cyan\", \"indigo\", \"pink\", \"chocolate\", \"grey\", \"lime\"]\n",
        "fig, ax = plt.subplots()\n",
        "for g in np.unique(train_labels):\n",
        "    idxs = np.where(train_labels == g)\n",
        "    ax.scatter(rd[0][idxs], rd[1][idxs], color=colors[g], label=f\"Digit {g}\")\n",
        "ax.legend()\n",
        "#----------------------------------------------------------------#"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Us8v86Y4rH05"
      },
      "source": [
        "# K-means clustering\n",
        "\n",
        "Awesome! These now actually look like some groupings. You may have noticed that we have not applied k-means clustering, yet clusters seem to form. How is this the case? Well an important thing to note is that **k-means clustering does not force groups into clusters, it simply identifies and \"colors\" clusters it sees**. We will now apply k-means clustering to the dataset to see how well it does.\n",
        "- [K-means](https://scikit-learn.org/stable/modules/generated/sklearn.cluster.KMeans.html)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2IdwEN7vrH05"
      },
      "outputs": [],
      "source": [
        "from sklearn.cluster import KMeans\n",
        "\n",
        "# Goal: Apply kmeans clustering to the above scatterplot\n",
        "\n",
        "## TODO: Create the following variables and execute the following code\n",
        "# kmeans: KMeans object with .fit() called on it (reduced training data passed in)\n",
        "\"\"\"\n",
        "Tips:\n",
        "- There are 10 digits... How many clusters (n_clusters) do you need?\n",
        "- Take a look at the \"init\" parameter and what it does in the documentation\n",
        "\"\"\"\n",
        "\n",
        "#----------------------------------------------------------------#\n",
        "rd = reduced_data.transpose()\n",
        "colors = [\"red\", \"orange\", \"yellow\", \"green\", \"cyan\", \"indigo\", \"pink\", \"chocolate\", \"grey\", \"lime\"]\n",
        "fig, ax = plt.subplots()\n",
        "for g in np.unique(kmeans.labels_):\n",
        "    idxs = np.where(kmeans.labels_ == g)\n",
        "    ax.scatter(rd[0][idxs], rd[1][idxs], color=colors[g], label=f\"Group {chr(g+65)}\")\n",
        "ax.legend()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gcr3l7OqrH06"
      },
      "source": [
        "Well, looks like kmeans got a bit confused... certain groups that were overlapping quite a bit are now considered \"distinct\" groups, leading to some misgrouped digits. It did, however, correctly classify some like 0!\n",
        "\n",
        "I hope this project gave you a new appreciation for dimensionality reduction, clustering, **and** their ___limitations___.\n",
        "\n",
        "Extensions:\n",
        "- Try other SK-learn clustering algoritms"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MI96shyNrH06"
      },
      "source": [
        "### Congratulations on completing the project! Check your results with the image(s) [here](https://drive.google.com/drive/folders/11VEiWTpxJHeIxgD-MuTrqexNRZGHl0iK?usp=drive_link) and then send this image to your group chat with your TA!"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "intro-course",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.9"
    },
    "orig_nbformat": 4,
    "vscode": {
      "interpreter": {
        "hash": "f3204eab9621eb34088b9e71fcdb754ce79a12fd6a4cd73f4898b86bb3d12718"
      }
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}